{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f90c12c",
   "metadata": {},
   "source": [
    "<h3> Prediction file structure: </h3>\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "results = joblib.load(<video.output_dir>/results/<video_name>.pkl)\n",
    "results = {\n",
    "  # A dictionary for each frame.\n",
    "  'vid_frame0.jpg': {\n",
    "    '2d_joints':       List[np.array(90,)],   # 45x 2D joints for each detection\n",
    "    '3d_joints':       List[np.array(45,3)],  # 45x 3D joints for each detection\n",
    "    'annotations':     List[Any],             # custom annotations for each detection\n",
    "    'appe':            List[np.array(4096,)], # appearance features for each detection\n",
    "    'bbox':            List[[x0 y0 w h]],     # 2D bounding box (top-left corner and dimensions) for each track (detections + ghosts)\n",
    "    'camera':          List[[tx ty tz]],      # camera translation (wrt image) for each detection\n",
    "    'camera_bbox':     List[[tx ty tz]],      # camera translation (wrt bbox) for each detection\n",
    "    'center':          List[[cx cy]],         # 2D center of bbox for each detection\n",
    "    'class_name':      List[int],             # class ID for each detection (0 for humans)\n",
    "    'conf':            List[float],           # confidence score for each detection\n",
    "    'frame_path':      'vid_frame0.jpg',      # Frame identifier\n",
    "    'loca':            List[np.array(99,)],   # location features for each detection\n",
    "    'mask':            List[mask],            # RLE-compressed mask for each detection\n",
    "    'pose':            List[np.array(229,)],  # pose feature (concatenated SMPL params) for each detection\n",
    "    'scale':           List[float],           # max(width, height) for each detection\n",
    "    'shot':            int,                   # Shot number\n",
    "    'size':            List[[imgw imgh]],     # Image dimensions for each detection\n",
    "    'smpl':            List[Dict_SMPL],       # SMPL parameters for each detection: betas (10), body_pose (23x3x3), global_orient (3x3)\n",
    "    'tid':             List[int],             # Track ID for each detection\n",
    "    'time':            int,                   # Frame number\n",
    "    'tracked_bbox':    List[[x0 y0 w h]],     # 2D bounding box (top-left corner and dimensions) for each detection\n",
    "    'tracked_ids':     List[int],             # Track ID for each detection\n",
    "    'tracked_time':    List[int],             # for each detection, time since it was last seen\n",
    "  },\n",
    "  'vid_frame1.jpg': {\n",
    "    ...\n",
    "  },\n",
    "  ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0056008d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#INFO] From:  /home/mint/Dev/CR7/pose_estimators/3D/4D-Humans/outputs/results/demo_weightlifting.pkl\n",
      "[#INFO] #N frames:  287\n",
      "[#INFO] #N unique ids:  3\n",
      "[#INFO] Longest tracking id:  1\n",
      "[#INFO] all_j3d shape:  (287, 45, 3)\n",
      "[#INFO] betas shape:  (287, 10)\n",
      "[#INFO] body_pose shape:  (287, 23, 3, 3)\n",
      "[#INFO] global_orient shape:  (287, 1, 3, 3)\n",
      "(287, 45, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def proc(path, focus_idx=0):\n",
    "    results = joblib.load(path)\n",
    "    print(\"[#INFO] From: \", path)\n",
    "    print(\"[#INFO] #N frames: \", len(results))\n",
    "    tracking_presence = {}\n",
    "    for fid, data in results.items():\n",
    "        for pid in data['tracked_ids']:\n",
    "            if pid not in tracking_presence:\n",
    "                tracking_presence[pid] = 1\n",
    "            else:\n",
    "                tracking_presence[pid] += 1\n",
    "    longest = max(tracking_presence.values())\n",
    "    longest_id = [k for k, v in tracking_presence.items() if v == longest][focus_idx]\n",
    "    print(\"[#INFO] #N unique ids: \", len(tracking_presence))\n",
    "    print(\"[#INFO] Longest tracking id: \", longest_id)\n",
    "    \n",
    "    all_j3d = []\n",
    "    betas = []\n",
    "    body_pose = []\n",
    "    global_orient = []\n",
    "    for fid, data in results.items():\n",
    "        if len(data['tid']) == 0:\n",
    "            continue\n",
    "        pid = data['tid'].index(longest_id)\n",
    "        # print(data['conf'])\n",
    "        # print(data['class_name'])\n",
    "        assert data['class_name'][pid] == 0   # person = 0\n",
    "        assert data['conf'][pid] > 0.85\n",
    "        \n",
    "        j3d = data['3d_joints'][pid]    # [45, 3]\n",
    "        all_j3d.append(j3d)\n",
    "        \n",
    "        smpl = data['smpl'][pid]    # [45, 3]\n",
    "        betas.append(smpl['betas'])\n",
    "        body_pose.append(smpl['body_pose'])\n",
    "        global_orient.append(smpl['global_orient'])\n",
    "        \n",
    "        # print(data['pose'][pid].shape)\n",
    "        # for k, v in data['smpl'][pid].items():\n",
    "        #     print(k, v.shape)\n",
    "        \n",
    "        # assert False\n",
    "        \n",
    "    all_j3d = np.stack(all_j3d)  # [T, 45, 3]\n",
    "    betas = np.stack(betas)  # [T, 10]\n",
    "    body_pose = np.stack(body_pose)  # [T, 23, 3, 3]\n",
    "    global_orient = np.stack(global_orient)  # [T, 1, 3, 3]\n",
    "    print(\"[#INFO] all_j3d shape: \", all_j3d.shape)\n",
    "    print(\"[#INFO] betas shape: \", betas.shape)\n",
    "    print(\"[#INFO] body_pose shape: \", body_pose.shape)\n",
    "    print(\"[#INFO] global_orient shape: \", global_orient.shape)\n",
    "    \n",
    "    out = {'3d_joints': all_j3d, 'betas': betas, 'body_pose': body_pose, 'global_orient': global_orient}\n",
    "    # import plotly.graph_objects as go\n",
    "    # x = all_j3d\n",
    "    # fig = go.Figure(data=[go.Scatter3d(x=x[0, :, 0], y=x[0, :, 1], z=x[0, :, 2], mode='markers')])\n",
    "    # fig.update_layout(scene=dict(\n",
    "    #     xaxis=dict(nticks=4, range=[-1, 1]),\n",
    "    #     yaxis=dict(nticks=4, range=[-1, 1]),\n",
    "    #     zaxis=dict(nticks=4, range=[-1, 1])\n",
    "    # ))\n",
    "    # fig.write_html('./test.html')\n",
    "    \n",
    "    print(all_j3d.shape)\n",
    "    # Write to pkl\n",
    "    # out_path = os.path.join(os.path.dirname(path), 'out.pkl')\n",
    "    out_path = os.path.join(f\"./{os.path.basename(path).split('.')[0]}.pkl\".format(longest_id))\n",
    "    joblib.dump(out, out_path)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# path = '/home/mint/Dev/CR7/pose_estimators/3D/4D-Humans/outputs/results/demo_cr7_1.pkl'\n",
    "path = '/home/mint/Dev/CR7/pose_estimators/3D/4D-Humans/outputs/results/demo_weightlifting.pkl'\n",
    "proc(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4D-humans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
